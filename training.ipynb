{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanstepanenko/Prueba-red/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6QASWerkGWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "899368a9-d569-41d8-af6b-6635fa979ebc"
      },
      "source": [
        "import os\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras import applications\n",
        "\n",
        "def model(amountClasses):\n",
        "    vgg=applications.vgg16.VGG16()\n",
        "    cnn=Sequential()\n",
        "    for layer in vgg.layers:\n",
        "        cnn.add(layer)\n",
        "    cnn.layers.pop()\n",
        "    for layer in cnn.layers:\n",
        "        layer.trainable=False\n",
        "    cnn.add(Dense(amountClasses,activation='softmax'))\n",
        "    \n",
        "    return cnn\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "root_dir = \"/content/gdrive/My Drive/TPS 5TO/Proyecto Final/Red Neuronal/Data/\"\n",
        "\n",
        "trainingData = root_dir + \"Training\"\n",
        "validationData = root_dir + \"Validation\"\n",
        "\n",
        "            \n",
        "#trainingData = 'C:/Users/stepa/Desktop/Prueba-red/data/training'\n",
        "#validationData = 'C:/Users/stepa/Desktop/Prueba-red/data/validation'\n",
        "\n",
        "epochs=4 # Number of epochs (\"itertions\") of the the data set in training\n",
        "length, height=224, 224 # Image size on pixels\n",
        "batchSize=2 # Number of pictures to be processed in each step\n",
        "steps=1000 # Number of batches proccesed in one iteration\n",
        "validationSteps=20 # Number of steps at the end of each iteration    \n",
        "conv1Filters=32 # Picture Depth\n",
        "conv2Filters=64 # Picture Depth\n",
        "filter1Size=(3, 3)\n",
        "filter2Size=(2, 2)\n",
        "poolSize=(2, 2) # Filter size used in the maxpooling\n",
        "classes=3 # Number of problems\n",
        "lr=0.0004 # Learning rate \n",
        "\n",
        "\n",
        "## Pictures preparation (pre-processing information)\n",
        "\n",
        "datagenTraining=ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0, # This parameter rotates the diferent pictures (oj)\n",
        "    zoom_range=0.2, \n",
        "    horizontal_flip=False) # Flips the picture\n",
        "\n",
        "datagenValidation=ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "trainingImage=datagenTraining.flow_from_directory(\n",
        "    trainingData,\n",
        "    target_size=(length, height),\n",
        "    batch_size=batchSize,\n",
        "    class_mode=\"categorical\") # We use this class mode when there are no classes/problem combinations\n",
        "\n",
        "validationImage=datagenValidation.flow_from_directory(\n",
        "    validationData,\n",
        "    target_size=(length, height),\n",
        "    batch_size=batchSize,\n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "# Network creation\n",
        "\n",
        "cnn=model(classes)\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',\n",
        "            optimizer=optimizers.Adam(lr=lr),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "\n",
        "cnn.fit_generator(\n",
        "    trainingImage,\n",
        "    steps_per_epoch=steps,\n",
        "    epochs=epochs,\n",
        "    validation_data=validationImage,\n",
        "    validation_steps=validationSteps)\n",
        "\n",
        "\n",
        "#target_dir = \"/content/gdrive/My Drive/\"\n",
        "#base_dir = root_dir + 'fastai-v3/data/'\n",
        "\n",
        "#target_dir = 'C:/Users/stepa/Desktop/Prueba-red/model'\n",
        "#if not os.path.exists(target_dir):\n",
        "  #os.mkdir(target_dir)\n",
        "cnn.save(\"model.h5\")\n",
        "cnn.save_weights(\"weigths.h5\")\n",
        "\n",
        "from google.colab import files\n",
        "#files.download(\"model.h5\")\n",
        "#files.download(\"weigths.h5\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Found 17 images belonging to 3 classes.\n",
            "Found 17 images belonging to 3 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 24s 0us/step\n",
            "Epoch 1/4\n",
            "1000/1000 [==============================] - 66s 66ms/step - loss: 1.0200 - acc: 0.5834 - val_loss: 0.9474 - val_acc: 0.6053\n",
            "Epoch 2/4\n",
            "1000/1000 [==============================] - 57s 57ms/step - loss: 0.9449 - acc: 0.5874 - val_loss: 0.9307 - val_acc: 0.6053\n",
            "Epoch 3/4\n",
            "1000/1000 [==============================] - 57s 57ms/step - loss: 0.9293 - acc: 0.5887 - val_loss: 0.9196 - val_acc: 0.6053\n",
            "Epoch 4/4\n",
            "1000/1000 [==============================] - 57s 57ms/step - loss: 0.9211 - acc: 0.5878 - val_loss: 0.8794 - val_acc: 0.6053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ecdd4d748785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weigths.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOG98gEm6Hux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a7948493-a8ae-4185-e105-e4c54610f10e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.utils import CustomObjectScope\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "length, height = 224, 224 # Same as in train.py\n",
        "#model1 = \"model.h5\"\n",
        "#weigths1 = \"weigths.h5\"\n",
        "\n",
        "#with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
        " # cnn = load_model(model)\n",
        "\n",
        "#from keras.models import load_model\n",
        "\n",
        "# Load files we already generated\n",
        "\n",
        "\n",
        "\n",
        "#cnn.load_weights(weigths)\n",
        "\n",
        "def predict(file): \n",
        "  image = load_img(file, target_size=(length, height))\n",
        "  image = img_to_array(image)\n",
        "  image = np.expand_dims(image, axis=0) # On axis 0 or first dimention we add a new dimention\n",
        "  predictionArray = cnn.predict(image) # Format: [[1,0]]. On the first dimention it have a number 1 when the prediction is the correct one\n",
        "  result = predictionArray[0] \n",
        "  answer = np.argmax(result) # Get index of the maximum result value\n",
        "  if answer == 0:\n",
        "    print(\"Prediction: Problem 1\")\n",
        "  elif answer == 1:\n",
        "    print(\"Prediction: Problem 2\")\n",
        "  elif answer == 2:\n",
        "    print(\"Prediction: Problem 3\")\n",
        "\n",
        "  return answer\n",
        "\n",
        "testImage = validationData + \"/Perdida en válvula/prueba.jpeg\"\n",
        "# How to predict:\n",
        "predict(testImage) # File from validation"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: Problem 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}